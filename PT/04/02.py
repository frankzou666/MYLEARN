"""
Author:
Purpose:
Dateï¼š
"""

import argparse
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt


tf._compat.disable_v2_behavior()

def getargs():
    """
    :arg
    :return   programare guemnts
    :date
    """
    argparser = argparse.ArgumentParser(description='say')
    argparser.add_argument('--name', default='world!', help='name message')
    return argparser.parse_args()


def main():
    """the entrance of this file"""
    tf._compat.disable_v2_behavior()
    epochs = 100
    learning_rate =0.1
    m = 100
    x_train = np.asarray([-0.4261841516318804, 0.3986219114346206, 0.25843662542456697, 0.6557125089385676, 0.5132942452256296,
     -0.17341038571864528, 0.1704281304886192, 0.006636556869090423, 0.5777065478102266, -0.7754951840428569,
     0.5072177035860611, -0.24651162415457234, -0.9248360504964424, 0.4367809704562706, 0.8987035341293801,
     0.16768311469090316, -0.22236117218781157, 0.02635284005888066, 0.12900677868620775, -0.2966059853490098,
     -0.03988705159909625, 0.3709483762055503, 0.593494653246493, -0.5940465393843014, -0.18509584650978556,
     0.07315471758189224, -0.2089280655980129, 0.017164937648545167, 0.594705095298579, 0.3862270893091169,
     0.1283938954251184, -0.24630595628006352, -0.012654114248151636, 0.26587692176546, 0.1277436759051707,
     0.3446334615852788, 0.45476651701871296, -0.07424532439392201, 0.042584572922337804, 0.7056764393128422,
     -0.4107810116346484, 0.39633350105519316, -0.2894819176887371, 0.45821262131487867, 0.039728813914657234,
     0.8534316060358133, 0.16008743747041837, -0.2300258945265282, 0.9773254906893873, 0.16707953746197896,
     -0.7155397791529822, 0.3757630918822584, 0.10588344930225874, 0.11397294555361627, 0.3129161442369282,
     -0.46706040018154177, 0.17931467398895912, 0.23766508427076505, -0.37317799010933167, 0.5538052614477342,
     0.16572249742755962, -0.19817613163367612, 0.09537478855950351, 0.8909117827126909, -0.40296417507405935,
     0.2658720770154443, -0.260811047286132, -0.22406081604982653, -0.08747600814003313, 0.10875127911899213,
     -0.5005517732575541, -0.27571904656373336, 0.5049193844994383, 0.4893654125818518, 0.15024871598098,
     -0.7612324829240514, 0.3687702704089147, -0.24891047965107635, -0.34053719942964933, -0.055441019043452215,
     0.22344254399696428, 0.3543470303461552, -0.5324100518363762, -0.5498488602427292, 0.4600725334903748,
     1.453808700545797, 0.4925749864779123, -0.33903658042046675, 0.18641140584312363, 0.07041278288062731,
     -1.0138261357409055, 0.21148872474081515, 0.2150402755940517, -0.39105621838381, -0.21822991084776203,
     0.3335051535618301, -0.2967777955468548, 0.017743399346178572, -0.016985178773295768, -0.5184778932313681])


    y_train = np.asarray([0.7231067414590295, 0.7917698059205124, 0.6505126853200446, 0.717567998782229, 0.7917910306434132,
     0.626305342138065, 0.7850801018153357, 0.7465908892936047, 0.979652757765269, 0.5114215550055552,
     0.8472667641268278, 0.8779092550674015, 0.44040516318208395, 0.6411223110865296, 0.8818507584748002,
     0.7979595492261672, 0.7609991137228502, 0.39367394563243896, 0.77714757802481, 0.5954904456397052,
     0.6990677244782736, 0.8110412899691564, 0.830054813104318, 0.5219843259272196, 0.6979893560696895,
     0.6376085642161405, 0.6970438909281281, 0.694066408641114, 0.8649335404667269, 0.7629878226872281,
     0.7333794890041777, 0.6987002377140721, 0.7799245443722372, 0.5790895383294834, 0.6974444304418077,
     0.5678274224099894, 0.6833304208660833, 0.6793469753699848, 0.6278020632767234, 0.648302194927544,
     0.7559319092869491, 0.6364108601089784, 0.6311142583259831, 0.7011015319783341, 0.6627896942031527,
     1.0249936501281254, 0.5629918474998203, 0.4608505884878962, 0.8227467331008393, 0.5867655261785991,
     0.3605471731348848, 0.7776114885313425, 0.6039176669379447, 0.8307142934262282, 0.6977956276113143,
     0.6625628793896337, 0.6007249573703396, 0.6657369622076142, 0.799171096082306, 0.8426103669995099,
     0.8082825453174485, 0.6566431932675134, 0.7279505242501467, 0.8119279877004458, 0.5689039735109529,
     0.6994237603537238, 0.6788977623158691, 0.4407807643436466, 0.6313076998389966, 0.6895289330973577,
     0.40221716659441603, 0.7109667705055335, 0.9056480933627356, 0.6680802618776114, 0.827026925697014,
     0.4991631034947056, 0.773191106011005, 0.6291511679970033, 0.6317813114097862, 0.7952522468548168,
     0.6802346764791813, 0.8438477524417688, 0.8822147197478858, 0.6114191842281071, 0.8058909220589995,
     1.0312320081201574, 0.8890641502838211, 0.621963741077801, 0.7074521177888892, 0.767062934409359,
     0.695617414354292, 0.9122971136981229, 0.7732119826103264, 0.6193793626947011, 0.49943237241136573,
     0.8088164889894341, 0.5270890075359937, 0.8328294074266125, 0.9409078978385461, 0.6042945424160399])

    w = tf.Variable(np.random.randn(),name='weight')
    b = tf.Variable(np.random.randn(), name='bias')
    x = tf.compat.v1.placeholder(dtype=tf.float32)
    y = tf.compat.v1.placeholder(dtype=tf.float32)

    # h= wx+b
    h = tf.add(tf.multiply(w,x),b)
    cost_function =tf.reduce_sum(tf.pow((h-y),2))/(2*m)

    grad = tf.compat.v1.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)

    init = tf.compat.v1.global_variables_initializer()

    with tf.compat.v1.Session() as sess:
        sess.run(init)
        for i, j in zip(x, y):
            sess.run(grad, feed_dict={x: i, y: j})






if __name__ == '__main__':
    main()
